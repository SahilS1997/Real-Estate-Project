{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scrapping Project - Makaan.com",
      "provenance": [],
      "authorship_tag": "ABX9TyMlz2qSBKlm6qjzCF3kyjOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilS1997/Real-Estate-Project/blob/main/Web_Scrapping_Project_Makaan_com.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neyjJf6fp-lu"
      },
      "source": [
        "##Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZywp0gAqDSp"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KgGFvosqRvX"
      },
      "source": [
        "##WebScrapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6IrujKzq1KS",
        "outputId": "d66f1068-e489-47a6-84d7-463ebe544dae"
      },
      "source": [
        "base_url = 'https://www.makaan.com/hyderabad-residential-property/buy-property-in-hyderabad-city?page='\n",
        "\n",
        "ow = [] #owner info\n",
        "bhk = [] #bhk info\n",
        "p = [] #price info\n",
        "s = [] #size info\n",
        "loc = [] #location info\n",
        "st = [] #status info\n",
        "pps = [] #price per sqft info\n",
        "\n",
        "for i in range(1,51):\n",
        "  time.sleep(3)\n",
        "  print(f'going to scrap data from {i} page')\n",
        "  clear_output(wait=True)\n",
        "  url = base_url+str(i)\n",
        "  req = requests.get(url)\n",
        "  soup = BeautifulSoup(req.text,'html')\n",
        "\n",
        "  #owner info\n",
        "  ow_info = soup.findAll('span',attrs={'class':'seller-type'})\n",
        "  for j in ow_info:\n",
        "    ow.append(j.text)\n",
        "  \n",
        "  #bhk info\n",
        "  bhk_info = soup.findAll('div',attrs={'class':'title-line'})\n",
        "  for j in bhk_info:\n",
        "    bhk.append(j.strong.span.text)\n",
        "\n",
        "  #price info\n",
        "  p_info = soup.findAll('div',attrs={'data-type':'price-link'})\n",
        "  for  j in p_info:\n",
        "    p.append(j.text)\n",
        "  \n",
        "  #size info\n",
        "  s_info = soup.findAll(\"td\",attrs={'class':'size'})\n",
        "  for j in s_info:\n",
        "    s.append(j.text)\n",
        "  \n",
        "  #location info\n",
        "  loc_info = soup.findAll('span',attrs={'itemprop':'addressLocality'})\n",
        "  for j in loc_info:\n",
        "    loc.append(j.text)\n",
        "  \n",
        "    #status info\n",
        "  st_info = soup.findAll('td',attrs={'class':'val'})\n",
        "  for i in st_info:\n",
        "    st.append(i.text)\n",
        "\n",
        "  #price per sqft info\n",
        "  pps_info = soup.findAll('td',attrs={'class':'lbl rate'})\n",
        "  for j in pps_info:\n",
        "    pps.append(j.text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "going to scrap data from 50 page\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTAhRpQOseOe"
      },
      "source": [
        "##Convert Scrapped Data into Structured format using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWhGZt96sdqI"
      },
      "source": [
        "data = pd.DataFrame({'Owner_inf' : ow,\n",
        "              'Bhk_info' : bhk,\n",
        "              'Price' : p,\n",
        "              'Locality' : loc,\n",
        "              'Area_sqft' : s,\n",
        "              'Status' : st,\n",
        "              'Price_Per_sqft' : pps})\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcd4jdZItfh4"
      },
      "source": [
        "#Export into .csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4hwf27ytfqE"
      },
      "source": [
        "data.to_csv('web_scrapped.csv',index=False) #index = false to exclude index column"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}